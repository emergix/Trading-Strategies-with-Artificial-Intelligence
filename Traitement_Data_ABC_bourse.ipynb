{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea36fe7c",
   "metadata": {},
   "source": [
    "# Recuperation des fichiers d'update envoyés par ABC Bourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9911a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 fichiers texte récupérés.\n"
     ]
    }
   ],
   "source": [
    "import imaplib\n",
    "import email\n",
    "import zipfile\n",
    "import io\n",
    "from email.header import decode_header\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "\n",
    "# Connexion à la boîte mail\n",
    "username = \"croissant.olivier@wanadoo.fr\"\n",
    "password = \"Liberty_orange_396939\"\n",
    "imap_server = \"imap.orange.fr\"\n",
    "\n",
    "username = \"croissant.olivier@wanadoo.fr\"\n",
    "password = \"Liberty_orange_3969\"\n",
    "imap_server = \"imap.orange.fr\"\n",
    "\n",
    "# Se connecter au serveur IMAP\n",
    "mail = imaplib.IMAP4_SSL(imap_server)\n",
    "mail.login(username, password)\n",
    "\n",
    "# Sélectionner la boîte spécifique \"a_A_abc_bourse\"\n",
    "mail.select(\"INBOX/a_A_abc_bourse\")\n",
    "\n",
    "# Recherche de tous les emails\n",
    "status, messages = mail.search(None, \"ALL\")\n",
    "\n",
    "# Récupérer les ID des emails\n",
    "email_ids = messages[0].split()\n",
    "\n",
    "# Tableau pour stocker le contenu des fichiers texte\n",
    "A = []\n",
    "\n",
    "for num in email_ids:\n",
    "    # Récupérer l'email brut\n",
    "    status, msg_data = mail.fetch(num, '(RFC822)')\n",
    "\n",
    "    # Parser l'email\n",
    "    msg = email.message_from_bytes(msg_data[0][1])\n",
    "\n",
    "    # Parcourir chaque partie du mail à la recherche des fichiers attachés\n",
    "    for part in msg.walk():\n",
    "        content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "        if \"attachment\" in content_disposition:\n",
    "            filename = part.get_filename()\n",
    "            if filename and filename.endswith('.zip'):\n",
    "                # Décodage éventuel du nom de fichier\n",
    "                decoded_filename, encoding = decode_header(filename)[0]\n",
    "                if isinstance(decoded_filename, bytes):\n",
    "                    filename = decoded_filename.decode(encoding if encoding else \"utf-8\")\n",
    "                \n",
    "                # Récupération du contenu ZIP en mémoire\n",
    "                zip_content = part.get_payload(decode=True)\n",
    "                \n",
    "                # Ouvrir le ZIP en mémoire\n",
    "                with zipfile.ZipFile(io.BytesIO(zip_content)) as z:\n",
    "                    # Parcourir les fichiers dans le ZIP\n",
    "                    for file_in_zip in z.namelist():\n",
    "                        if file_in_zip.endswith('.txt'):\n",
    "                            # Lire le contenu du fichier texte\n",
    "                            with z.open(file_in_zip) as txt_file:\n",
    "                                attachment_content = txt_file.read().decode('utf-8', errors='ignore')\n",
    "                                A.append(attachment_content)\n",
    "\n",
    "# Déconnexion propre\n",
    "mail.logout()\n",
    "\n",
    "# Maintenant, A[i] contient le texte de chaque fichier attaché extrait des ZIP\n",
    "print(f\"{len(A)} fichiers texte récupérés.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6d997",
   "metadata": {},
   "source": [
    "https://www.abcbourse.com/download/libelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcf3a0",
   "metadata": {},
   "source": [
    "# Rajout des ISIN non connus dans la base vendue par abc bourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2786a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "libelles_sup =[\n",
    "['FR0014005DA7',\"Exclusive Networks\"],\n",
    "['FR00140085W6p',\"M.R.M\"],\n",
    "['CH1145930991p',\"21Shares Cosmos Staking ETP\"],\n",
    "['LU2056739464p',\"Lyxor MSCI World Climate Change (DR) UCITS ETF\"],\n",
    "['LU1602145200p',\"Amundi Index Equity Global Multi Smart Allocation Scientific Beta UCITS ETF\"],\n",
    "['LU1523099700p',\"Lyxor Bund Daily Short UCITS ETF\"],\n",
    "['LU0533034129p',\"Lyxor MSCI World Communication Services TR UCITS ETF\"],\n",
    "['LU2198884145p',\"Lyxor Net Zero 2050 S&P 500 Climate PAB (DR) UCITS ETF\"],\n",
    "['CH1177361008p',\"21Shares The Sandbox ETP\"],\n",
    "['CH1161102699p',\"21Shares Decentraland ETP\"],\n",
    "['LU0246033426p',\"BNP Paribas Easy EURO STOXX 50 UCITS ETF\"],\n",
    "['FR0011363423p',\"Lyxor MSCI USA ESG Broad CTB (DR) UCITS ETF\"],\n",
    "['LU0533033824p',\"Lyxor MSCI World Materials TR UCITS ETF\"],\n",
    "['LU0488317701p',\"Lyxor NYSE Arca Gold BUGS (DR) UCITS ETF\"],\n",
    "['LU1525419294p',\"Amundi Index US Government Inflation-linked Bond UCITS ETF\"],\n",
    "['LU2056738144p',\"Lyxor MSCI EM ESG Climate Transition CTB UCITS ETF\"],\n",
    "['LU1799934903p',\"Lyxor MSCI World ESG Trend Leaders (DR) UCITS ETF\"],\n",
    "['FR0010296061p',\"Lyxor MSCI USA ESG Broad CTB (DR) UCITS ETF\"],\n",
    "['LU2198883410p',\"Lyxor Net Zero 2050 S&P 500 Climate PAB (DR) UCITS ETF\"],\n",
    "['LU1437024992p',\"Amundi MSCI Brazil UCITS ETF\"],\n",
    "['CH0514065058p',\"21Shares Short Bitcoin ETP\"],\n",
    "['LU1859445063p',\"BNP Paribas Easy FTSE EPRA/NAREIT Developed Europe UCITS ETF\"],\n",
    "['FR0011607084p',\"Amundi US Treasury 10Y Daily (-2x) Inverse UCITS ETF\"],\n",
    "['FR0014005OJ5p',\"ACTICOR BIOTECH\"],\n",
    "['FR0013421286p',\"ALPHA MOS\"],\n",
    "['FR00140069V2p',\"GROUPE BERKEM\"],\n",
    "['FR0004152882p',\"CLASQUIN\"],\n",
    "['FR0010285965p',\"1000MERCIS\"],\n",
    "['FR0013495298p',\"GAUSSIN\"],\n",
    "['FR0000035818p',\"ESKER\"],\n",
    "['FR001400JAL7p',\"ADOMOS\"],\n",
    "['FR001400MV37p',\"NEOVACS\"],\n",
    "['FR0014005DA7p',\"EXCLUSIVE NETWORKS\"],\n",
    "['IE000BI8OT95p',\"Amundi Core MSCI World UCITS ETF\"],\n",
    "['FR001400SVN0p',\"Drone Volt\"],\n",
    "['FR001400SOY2p',\"Acheter-Louer.fr\"],\n",
    "['FR001400X2S4p',\"AtoS SE\"],\n",
    "['IE000NITTFF2n',\"iShares Russell 1000 Growth UCITS ETF USD (Acc), émetteur iShares VII plc\"],\n",
    "['FR001400SUB7p',\"Compagnie du Cambodge (CAMBODGE NOM.)\"],\n",
    "['LU3038520774p',\"Amundi STOXX Europe Defense UCITS ETF (Acc)\"],\n",
    "['IE000DQLYVB9p',\"iShares S&P 500 Swap PEA UCITS ETF EUR (Acc) – ticker SPEA\"],\n",
    "['IE00BWBXM500n',\"SPDR S&P U.S. Financials Select Sector UCITS ETF (Acc) (USD)\"],\n",
    "['IE00BMVB5R75n',\"Vanguard LifeStrategy 80% Equity UCITS ETF (EUR) Acc\"],\n",
    "['IE00BMTX1Y45n',\"iShares S&P 500 Swap UCITS ETF USD (Acc)\"],\n",
    "['IE000VA628D5p',\"iShares S&P 500 Top 20 UCITS ETF (USD) (Acc) – ticker SP20\"],\n",
    "['LU2999653251p',\"Younited Financial (action ordinaire)\"],\n",
    "['LU3047998896p',\"BNP Paribas Easy Bloomberg Europe Defense UCITS ETF (Acc)\"],\n",
    "['IE000OJ5TQP4p',\"HANetf “Future of Defence” UCITS ETF (ticker NATO/ASWC suivant marché)\"],\n",
    "['FR001400ZU25p',\"SAFE SA (ex-Safe Orthopaedics) – coté Euronext Growth\"],\n",
    "['FR0014010H01p',\"Semco Technologies (Euronext Growth Paris)\"],\n",
    "['FR001400WXE7p',\"PREATONI GROUP (Euronext Access+)\"],\n",
    "['ES0105910006p',\"SAJA Real Estate SOCIMI, S.A\"],\n",
    "['FR0014010QE1p',\"Hopium SA\"],\n",
    "['FR0014010856p',\"Neovacs SA\"],\n",
    "['IE000YYE6WK5p',\"VanEck Defense UCITS ETF (A USD Acc)\"],\n",
    "['IE000YU9K6K2p',\"VanEck Space Innovators UCITS ETF (A USD Acc) – ticker JEDI\"],\n",
    "['ES0105908000p',\"Inmolecule Nanotech, S.A\"],\n",
    "['DE000A2QP372n',\"iShares EURO STOXX Banks 30-15 UCITS ETF (DE)\"],\n",
    "['IE000M7V94E1p',\"VanEck Uranium and Nuclear Technologies UCITS ETF.\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9306cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISIN manquants manuellement ajoutés\n",
    "df_sup = pd.DataFrame(libelles_sup, columns=[\"ISIN\", \"Nom\"])\n",
    "df_sup[\"Ticker\"] = \"inconnu\"  # Valeur par défaut pour les tickers manquants\n",
    "\n",
    "# Chargement des fichiers CSV\n",
    "df_isin1 = pd.read_csv(\"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\libelles.csv\", sep=\";\")\n",
    "df_isin2 = pd.read_csv(\"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\libelles2.csv\", sep=\";\")\n",
    "\n",
    "# Fusion finale avec index réinitialisé\n",
    "df_isin = pd.concat([df_isin1, df_isin2, df_sup], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24223b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nombre total de lignes extraites depuis A : 260926\n",
      "\n",
      "✅ Tous les ISIN ont été trouvés.\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier ISIN/Nom/Ticker\n",
    "\n",
    "isin_to_nom = df_isin.set_index(\"ISIN\")[\"Nom\"].to_dict()\n",
    "isin_to_ticker = df_isin.set_index(\"ISIN\")[\"Ticker\"].to_dict()\n",
    "\n",
    "# Parser chaque entrée de A pour construire un seul DataFrame\n",
    "all_rows = []\n",
    "for a in A:\n",
    "    # Nettoyage des décimales (virgule -> point)\n",
    "    a_clean = a.replace(\",\", \".\")\n",
    "    lines = a_clean.strip().splitlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(\";\")\n",
    "        if len(parts) == 7:\n",
    "            isin, date, open_, high, low, close, volume = parts\n",
    "            nom = isin_to_nom.get(isin, \"inconnu\")\n",
    "            ticker = isin_to_ticker.get(isin, \"inconnu\")\n",
    "            all_rows.append({\n",
    "                \"ISIN\": isin,\n",
    "                \"Date\": date,\n",
    "                \"Open\": float(open_),\n",
    "                \"High\": float(high),\n",
    "                \"Low\": float(low),\n",
    "                \"Close\": float(close),\n",
    "                \"Volume\": int(volume),\n",
    "                \"Nom\": nom,\n",
    "                \"Ticker\": ticker,\n",
    "                \"Source\":\"Daily Update\"\n",
    "            })\n",
    "\n",
    "# Création du DataFrame final\n",
    "df_from_A = pd.DataFrame(all_rows)\n",
    "\n",
    "# Affichage\n",
    "print(f\"✅ Nombre total de lignes extraites depuis A : {len(df_from_A)}\")\n",
    "\n",
    "# Optionnel : lister les ISIN inconnus avec leur fréquence\n",
    "isin_inconnus = [row[\"ISIN\"] for row in all_rows if row[\"Nom\"] == \"inconnu\"]\n",
    "counter = Counter(isin_inconnus)\n",
    "if counter:\n",
    "    print(\"\\n🔎 ISIN inconnus rencontrés :\")\n",
    "    for isin, count in counter.items():\n",
    "        print(f\"{isin} : {count} fois\")\n",
    "else:\n",
    "    print(\"\\n✅ Tous les ISIN ont été trouvés.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1131d",
   "metadata": {},
   "source": [
    "# Traitement de la base historique de abc bourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1b83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Charger l’historique\n",
    "fichier_path1 = \"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\ActionFrancaise_ListeA.csv\"\n",
    "fichier_path2 = \"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\ActionFrancaise_ListeA1.csv\"\n",
    "\n",
    "# Chargement des deux fichiers CSV avec le bon séparateur\n",
    "df1 = pd.read_csv(fichier_path1, sep=';', encoding='utf-8')\n",
    "df2 = pd.read_csv(fichier_path2, sep=';', encoding='ISO-8859-1')\n",
    "\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True).drop_duplicates(subset=[\"ISIN\", \"Date\"])\n",
    "df_concat[\"Source\"] = \"Historique\"\n",
    "\n",
    "# 1. Appliquer les dictionnaires aux données historiques\n",
    "df_concat[\"Nom\"] = df_concat[\"ISIN\"].map(isin_to_nom).fillna(\"inconnu\")\n",
    "df_concat[\"Ticker\"] = df_concat[\"ISIN\"].map(isin_to_ticker).fillna(\"inconnu\")\n",
    "\n",
    "# 4. Fusion avec les nouvelles données\n",
    "df_final = pd.concat([df_concat, df_from_A], ignore_index=True).drop_duplicates(subset=[\"ISIN\", \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ac7faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1959900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa89b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Tous les ISIN ont un nom.\n"
     ]
    }
   ],
   "source": [
    "isin_manquants = df_final[df_final[\"Nom\"] == \"inconnu\"][\"ISIN\"]\n",
    "if not isin_manquants.empty:\n",
    "    print(\"\\n🚨 ISIN inconnus dans le dataset final :\")\n",
    "    print(isin_manquants.value_counts())\n",
    "else:\n",
    "    print(\"\\n✅ Tous les ISIN ont un nom.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9d0da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(isin_manquants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf01807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_isin_column(df, column=\"ISIN\"):\n",
    "    \"\"\"\n",
    "    Nettoie la colonne ISIN en supprimant la dernière lettre\n",
    "    si c'est un caractère alphabétique.\n",
    "    \"\"\"\n",
    "    def sanitize(isin):\n",
    "        isin = str(isin)\n",
    "        if isin and isin[-1].isalpha():\n",
    "            return isin[:-1]\n",
    "        return isin\n",
    "    \n",
    "    df[column] = df[column].apply(sanitize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e78d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = clean_isin_column(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f9e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Source</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR0000064578</td>\n",
       "      <td>26/07/90</td>\n",
       "      <td>14.350</td>\n",
       "      <td>14.350</td>\n",
       "      <td>14.350</td>\n",
       "      <td>14.350</td>\n",
       "      <td>0</td>\n",
       "      <td>Covivio</td>\n",
       "      <td>Historique</td>\n",
       "      <td>COV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR0000054215</td>\n",
       "      <td>26/07/90</td>\n",
       "      <td>65.250</td>\n",
       "      <td>65.250</td>\n",
       "      <td>65.250</td>\n",
       "      <td>65.250</td>\n",
       "      <td>0</td>\n",
       "      <td>Unibel</td>\n",
       "      <td>Historique</td>\n",
       "      <td>UNBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR0000064578</td>\n",
       "      <td>27/07/90</td>\n",
       "      <td>14.300</td>\n",
       "      <td>14.300</td>\n",
       "      <td>14.300</td>\n",
       "      <td>14.300</td>\n",
       "      <td>0</td>\n",
       "      <td>Covivio</td>\n",
       "      <td>Historique</td>\n",
       "      <td>COV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR0000054215</td>\n",
       "      <td>27/07/90</td>\n",
       "      <td>63.270</td>\n",
       "      <td>63.270</td>\n",
       "      <td>63.270</td>\n",
       "      <td>63.270</td>\n",
       "      <td>0</td>\n",
       "      <td>Unibel</td>\n",
       "      <td>Historique</td>\n",
       "      <td>UNBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR0000064578</td>\n",
       "      <td>30/07/90</td>\n",
       "      <td>13.720</td>\n",
       "      <td>13.720</td>\n",
       "      <td>13.720</td>\n",
       "      <td>13.720</td>\n",
       "      <td>0</td>\n",
       "      <td>Covivio</td>\n",
       "      <td>Historique</td>\n",
       "      <td>COV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959895</th>\n",
       "      <td>US2220702037</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>3.360</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.358</td>\n",
       "      <td>3.401</td>\n",
       "      <td>2884</td>\n",
       "      <td>Coty Inc.</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>COTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959896</th>\n",
       "      <td>FR0000124570</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.220</td>\n",
       "      <td>13.900</td>\n",
       "      <td>14.100</td>\n",
       "      <td>103690</td>\n",
       "      <td>OPmobility (ex Plastic Omnium)</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>OPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959897</th>\n",
       "      <td>LU0569974404</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>30.880</td>\n",
       "      <td>31.740</td>\n",
       "      <td>30.740</td>\n",
       "      <td>31.640</td>\n",
       "      <td>324105</td>\n",
       "      <td>Aperam</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>APAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959898</th>\n",
       "      <td>BE0003853703</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>68.400</td>\n",
       "      <td>69.500</td>\n",
       "      <td>68.300</td>\n",
       "      <td>69.500</td>\n",
       "      <td>18700</td>\n",
       "      <td>Montea C.V.A.</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>MONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959899</th>\n",
       "      <td>FR0010221234</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>3.555</td>\n",
       "      <td>3.730</td>\n",
       "      <td>3.495</td>\n",
       "      <td>3.710</td>\n",
       "      <td>2129082</td>\n",
       "      <td>Eutelsat Com.</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>ETL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1959900 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ISIN      Date    Open    High     Low   Close   Volume  \\\n",
       "0        FR0000064578  26/07/90  14.350  14.350  14.350  14.350        0   \n",
       "1        FR0000054215  26/07/90  65.250  65.250  65.250  65.250        0   \n",
       "2        FR0000064578  27/07/90  14.300  14.300  14.300  14.300        0   \n",
       "3        FR0000054215  27/07/90  63.270  63.270  63.270  63.270        0   \n",
       "4        FR0000064578  30/07/90  13.720  13.720  13.720  13.720        0   \n",
       "...               ...       ...     ...     ...     ...     ...      ...   \n",
       "1959895  US2220702037  03/10/25   3.360   3.401   3.358   3.401     2884   \n",
       "1959896  FR0000124570  03/10/25  14.000  14.220  13.900  14.100   103690   \n",
       "1959897  LU0569974404  03/10/25  30.880  31.740  30.740  31.640   324105   \n",
       "1959898  BE0003853703  03/10/25  68.400  69.500  68.300  69.500    18700   \n",
       "1959899  FR0010221234  03/10/25   3.555   3.730   3.495   3.710  2129082   \n",
       "\n",
       "                                    Nom        Source Ticker  \n",
       "0                               Covivio    Historique    COV  \n",
       "1                                Unibel    Historique   UNBL  \n",
       "2                               Covivio    Historique    COV  \n",
       "3                                Unibel    Historique   UNBL  \n",
       "4                               Covivio    Historique    COV  \n",
       "...                                 ...           ...    ...  \n",
       "1959895                       Coty Inc.  Daily Update   COTY  \n",
       "1959896  OPmobility (ex Plastic Omnium)  Daily Update    OPM  \n",
       "1959897                          Aperam  Daily Update   APAM  \n",
       "1959898                   Montea C.V.A.  Daily Update   MONT  \n",
       "1959899                   Eutelsat Com.  Daily Update    ETL  \n",
       "\n",
       "[1959900 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c03e49",
   "metadata": {},
   "source": [
    "# Creation de la base de donnée postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ef7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"bourse\",\n",
    "    user=\"olivier\",\n",
    "    password=\"cccc\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0095323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3  # Pas besoin d'installation\n",
    "from sqlalchemy import create_engine,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23084768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Table ABC_Bourse supprimée si elle existait.\n",
      "✅ Table ABC_Bourse créée dans la base 'bourse.db'\n"
     ]
    }
   ],
   "source": [
    "# Supposons que df_final est prêt et contient les colonnes nettoyées suivantes :\n",
    "# [\"ISIN\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Nom\", \"Ticker\", \"source\"]\n",
    "\n",
    "# Nettoyage : conversion Date + types numériques\n",
    "\n",
    "df_final[\"Date\"] = pd.to_datetime(df_final[\"Date\"], format=\"%d/%m/%y\", errors=\"coerce\", dayfirst=True)\n",
    "df_final[\"Open\"] = pd.to_numeric(df_final[\"Open\"], errors=\"coerce\")\n",
    "df_final[\"High\"] = pd.to_numeric(df_final[\"High\"], errors=\"coerce\")\n",
    "df_final[\"Low\"] = pd.to_numeric(df_final[\"Low\"], errors=\"coerce\")\n",
    "df_final[\"Close\"] = pd.to_numeric(df_final[\"Close\"], errors=\"coerce\")\n",
    "df_final[\"Volume\"] = pd.to_numeric(df_final[\"Volume\"], errors=\"coerce\")\n",
    "\n",
    "# Connexion à la base SQLite locale\n",
    "#engine = create_engine('sqlite:///bourse.db')  # Remplacer par la chaîne de connexion à ta base (PostgreSQL, etc.)\n",
    "\n",
    "# Remplace par tes identifiants PostgreSQL\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:cccc@localhost:5432/bourse\")\n",
    "\n",
    "# Supprimer la table seulement si elle existe\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS ABC_Bourse\"))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"✅ Table ABC_Bourse supprimée si elle existait.\")\n",
    "\n",
    "# Création / remplacement de la table ABC_Bourse\n",
    "df_final.to_sql(\"ABC_Bourse\", con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"✅ Table ABC_Bourse créée dans la base 'bourse.db'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b035856",
   "metadata": {},
   "source": [
    "# Creation de la base de donnée Des codes ISIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43481ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isin = clean_isin_column(df_isin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3020648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total initial : 17613\n",
      "Nombre après déduplication : 7008\n"
     ]
    }
   ],
   "source": [
    "# On garde le premier enregistrement par ISIN (tu peux aussi faire 'last' selon ton besoin)\n",
    "df_isin_unique = df_isin.drop_duplicates(subset=\"ISIN\", keep=\"first\")\n",
    "\n",
    "# Vérif rapide\n",
    "print(f\"Nombre total initial : {len(df_isin)}\")\n",
    "print(f\"Nombre après déduplication : {len(df_isin_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca7fdc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Table ISIN_Metadata enregistrée dans la base bourse.db.\n"
     ]
    }
   ],
   "source": [
    "df_isin_unique.to_sql(\"ISIN_Metadata\", con=engine, if_exists=\"replace\", index=False)\n",
    "print(\"✅ Table ISIN_Metadata enregistrée dans la base bourse.db.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c296612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
