{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea36fe7c",
   "metadata": {},
   "source": [
    "# Recuperation des fichiers d'update envoy√©s par ABC Bourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9911a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 fichiers texte r√©cup√©r√©s.\n"
     ]
    }
   ],
   "source": [
    "import imaplib\n",
    "import email\n",
    "import zipfile\n",
    "import io\n",
    "from email.header import decode_header\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "\n",
    "# Connexion √† la bo√Æte mail\n",
    "username = \"croissant.olivier@wanadoo.fr\"\n",
    "password = \"Liberty_orange_396939\"\n",
    "imap_server = \"imap.orange.fr\"\n",
    "\n",
    "username = \"croissant.olivier@wanadoo.fr\"\n",
    "password = \"Liberty_orange_3969\"\n",
    "imap_server = \"imap.orange.fr\"\n",
    "\n",
    "# Se connecter au serveur IMAP\n",
    "mail = imaplib.IMAP4_SSL(imap_server)\n",
    "mail.login(username, password)\n",
    "\n",
    "# S√©lectionner la bo√Æte sp√©cifique \"a_A_abc_bourse\"\n",
    "mail.select(\"INBOX/a_A_abc_bourse\")\n",
    "\n",
    "# Recherche de tous les emails\n",
    "status, messages = mail.search(None, \"ALL\")\n",
    "\n",
    "# R√©cup√©rer les ID des emails\n",
    "email_ids = messages[0].split()\n",
    "\n",
    "# Tableau pour stocker le contenu des fichiers texte\n",
    "A = []\n",
    "\n",
    "for num in email_ids:\n",
    "    # R√©cup√©rer l'email brut\n",
    "    status, msg_data = mail.fetch(num, '(RFC822)')\n",
    "\n",
    "    # Parser l'email\n",
    "    msg = email.message_from_bytes(msg_data[0][1])\n",
    "\n",
    "    # Parcourir chaque partie du mail √† la recherche des fichiers attach√©s\n",
    "    for part in msg.walk():\n",
    "        content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "        if \"attachment\" in content_disposition:\n",
    "            filename = part.get_filename()\n",
    "            if filename and filename.endswith('.zip'):\n",
    "                # D√©codage √©ventuel du nom de fichier\n",
    "                decoded_filename, encoding = decode_header(filename)[0]\n",
    "                if isinstance(decoded_filename, bytes):\n",
    "                    filename = decoded_filename.decode(encoding if encoding else \"utf-8\")\n",
    "                \n",
    "                # R√©cup√©ration du contenu ZIP en m√©moire\n",
    "                zip_content = part.get_payload(decode=True)\n",
    "                \n",
    "                # Ouvrir le ZIP en m√©moire\n",
    "                with zipfile.ZipFile(io.BytesIO(zip_content)) as z:\n",
    "                    # Parcourir les fichiers dans le ZIP\n",
    "                    for file_in_zip in z.namelist():\n",
    "                        if file_in_zip.endswith('.txt'):\n",
    "                            # Lire le contenu du fichier texte\n",
    "                            with z.open(file_in_zip) as txt_file:\n",
    "                                attachment_content = txt_file.read().decode('utf-8', errors='ignore')\n",
    "                                A.append(attachment_content)\n",
    "\n",
    "# D√©connexion propre\n",
    "mail.logout()\n",
    "\n",
    "# Maintenant, A[i] contient le texte de chaque fichier attach√© extrait des ZIP\n",
    "print(f\"{len(A)} fichiers texte r√©cup√©r√©s.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6d997",
   "metadata": {},
   "source": [
    "https://www.abcbourse.com/download/libelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcf3a0",
   "metadata": {},
   "source": [
    "# Rajout des ISIN non connus dans la base vendue par abc bourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2786a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "libelles_sup =[\n",
    "['FR0014005DA7',\"Exclusive Networks\"],\n",
    "['FR00140085W6p',\"M.R.M\"],\n",
    "['CH1145930991p',\"21Shares Cosmos Staking ETP\"],\n",
    "['LU2056739464p',\"Lyxor MSCI World Climate Change (DR) UCITS ETF\"],\n",
    "['LU1602145200p',\"Amundi Index Equity Global Multi Smart Allocation Scientific Beta UCITS ETF\"],\n",
    "['LU1523099700p',\"Lyxor Bund Daily Short UCITS ETF\"],\n",
    "['LU0533034129p',\"Lyxor MSCI World Communication Services TR UCITS ETF\"],\n",
    "['LU2198884145p',\"Lyxor Net Zero 2050 S&P 500 Climate PAB (DR) UCITS ETF\"],\n",
    "['CH1177361008p',\"21Shares The Sandbox ETP\"],\n",
    "['CH1161102699p',\"21Shares Decentraland ETP\"],\n",
    "['LU0246033426p',\"BNP Paribas Easy EURO STOXX 50 UCITS ETF\"],\n",
    "['FR0011363423p',\"Lyxor MSCI USA ESG Broad CTB (DR) UCITS ETF\"],\n",
    "['LU0533033824p',\"Lyxor MSCI World Materials TR UCITS ETF\"],\n",
    "['LU0488317701p',\"Lyxor NYSE Arca Gold BUGS (DR) UCITS ETF\"],\n",
    "['LU1525419294p',\"Amundi Index US Government Inflation-linked Bond UCITS ETF\"],\n",
    "['LU2056738144p',\"Lyxor MSCI EM ESG Climate Transition CTB UCITS ETF\"],\n",
    "['LU1799934903p',\"Lyxor MSCI World ESG Trend Leaders (DR) UCITS ETF\"],\n",
    "['FR0010296061p',\"Lyxor MSCI USA ESG Broad CTB (DR) UCITS ETF\"],\n",
    "['LU2198883410p',\"Lyxor Net Zero 2050 S&P 500 Climate PAB (DR) UCITS ETF\"],\n",
    "['LU1437024992p',\"Amundi MSCI Brazil UCITS ETF\"],\n",
    "['CH0514065058p',\"21Shares Short Bitcoin ETP\"],\n",
    "['LU1859445063p',\"BNP Paribas Easy FTSE EPRA/NAREIT Developed Europe UCITS ETF\"],\n",
    "['FR0011607084p',\"Amundi US Treasury 10Y Daily (-2x) Inverse UCITS ETF\"],\n",
    "['FR0014005OJ5p',\"ACTICOR BIOTECH\"],\n",
    "['FR0013421286p',\"ALPHA MOS\"],\n",
    "['FR00140069V2p',\"GROUPE BERKEM\"],\n",
    "['FR0004152882p',\"CLASQUIN\"],\n",
    "['FR0010285965p',\"1000MERCIS\"],\n",
    "['FR0013495298p',\"GAUSSIN\"],\n",
    "['FR0000035818p',\"ESKER\"],\n",
    "['FR001400JAL7p',\"ADOMOS\"],\n",
    "['FR001400MV37p',\"NEOVACS\"],\n",
    "['FR0014005DA7p',\"EXCLUSIVE NETWORKS\"],\n",
    "['IE000BI8OT95p',\"Amundi Core MSCI World UCITS ETF\"],\n",
    "['FR001400SVN0p',\"Drone Volt\"],\n",
    "['FR001400SOY2p',\"Acheter-Louer.fr\"],\n",
    "['FR001400X2S4p',\"AtoS SE\"],\n",
    "['IE000NITTFF2n',\"iShares Russell 1000 Growth UCITS ETF USD (Acc), √©metteur iShares VII plc\"],\n",
    "['FR001400SUB7p',\"Compagnie du Cambodge (CAMBODGE NOM.)\"],\n",
    "['LU3038520774p',\"Amundi STOXX Europe Defense UCITS ETF (Acc)\"],\n",
    "['IE000DQLYVB9p',\"iShares S&P 500 Swap PEA UCITS ETF EUR (Acc) ‚Äì ticker SPEA\"],\n",
    "['IE00BWBXM500n',\"SPDR S&P U.S. Financials Select Sector UCITS ETF (Acc) (USD)\"],\n",
    "['IE00BMVB5R75n',\"Vanguard LifeStrategy 80% Equity UCITS ETF (EUR) Acc\"],\n",
    "['IE00BMTX1Y45n',\"iShares S&P 500 Swap UCITS ETF USD (Acc)\"],\n",
    "['IE000VA628D5p',\"iShares S&P 500 Top 20 UCITS ETF (USD) (Acc) ‚Äì ticker SP20\"],\n",
    "['LU2999653251p',\"Younited Financial (action ordinaire)\"],\n",
    "['LU3047998896p',\"BNP Paribas Easy Bloomberg Europe Defense UCITS ETF (Acc)\"],\n",
    "['IE000OJ5TQP4p',\"HANetf ‚ÄúFuture of Defence‚Äù UCITS ETF (ticker NATO/ASWC suivant march√©)\"],\n",
    "['FR001400ZU25p',\"SAFE SA (ex-Safe Orthopaedics) ‚Äì cot√© Euronext Growth\"],\n",
    "['FR0014010H01p',\"Semco Technologies (Euronext Growth Paris)\"],\n",
    "['FR001400WXE7p',\"PREATONI GROUP (Euronext Access+)\"],\n",
    "['ES0105910006p',\"SAJA Real Estate SOCIMI, S.A\"],\n",
    "['FR0014010QE1p',\"Hopium SA\"],\n",
    "['FR0014010856p',\"Neovacs SA\"],\n",
    "['IE000YYE6WK5p',\"VanEck Defense UCITS ETF (A USD Acc)\"],\n",
    "['IE000YU9K6K2p',\"VanEck Space Innovators UCITS ETF (A USD Acc) ‚Äì ticker JEDI\"],\n",
    "['ES0105908000p',\"Inmolecule Nanotech, S.A\"],\n",
    "['DE000A2QP372n',\"iShares EURO STOXX Banks 30-15 UCITS ETF (DE)\"],\n",
    "['IE000M7V94E1p',\"VanEck Uranium and Nuclear Technologies UCITS ETF.\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9306cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISIN manquants manuellement ajout√©s\n",
    "df_sup = pd.DataFrame(libelles_sup, columns=[\"ISIN\", \"Nom\"])\n",
    "df_sup[\"Ticker\"] = \"inconnu\"  # Valeur par d√©faut pour les tickers manquants\n",
    "\n",
    "# Chargement des fichiers CSV\n",
    "df_isin1 = pd.read_csv(\"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\libelles.csv\", sep=\";\")\n",
    "df_isin2 = pd.read_csv(\"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\libelles2.csv\", sep=\";\")\n",
    "\n",
    "# Fusion finale avec index r√©initialis√©\n",
    "df_isin = pd.concat([df_isin1, df_isin2, df_sup], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24223b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nombre total de lignes extraites depuis A : 260926\n",
      "\n",
      "‚úÖ Tous les ISIN ont √©t√© trouv√©s.\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier ISIN/Nom/Ticker\n",
    "\n",
    "isin_to_nom = df_isin.set_index(\"ISIN\")[\"Nom\"].to_dict()\n",
    "isin_to_ticker = df_isin.set_index(\"ISIN\")[\"Ticker\"].to_dict()\n",
    "\n",
    "# Parser chaque entr√©e de A pour construire un seul DataFrame\n",
    "all_rows = []\n",
    "for a in A:\n",
    "    # Nettoyage des d√©cimales (virgule -> point)\n",
    "    a_clean = a.replace(\",\", \".\")\n",
    "    lines = a_clean.strip().splitlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(\";\")\n",
    "        if len(parts) == 7:\n",
    "            isin, date, open_, high, low, close, volume = parts\n",
    "            nom = isin_to_nom.get(isin, \"inconnu\")\n",
    "            ticker = isin_to_ticker.get(isin, \"inconnu\")\n",
    "            all_rows.append({\n",
    "                \"ISIN\": isin,\n",
    "                \"Date\": date,\n",
    "                \"Open\": float(open_),\n",
    "                \"High\": float(high),\n",
    "                \"Low\": float(low),\n",
    "                \"Close\": float(close),\n",
    "                \"Volume\": int(volume),\n",
    "                \"Nom\": nom,\n",
    "                \"Ticker\": ticker,\n",
    "                \"Source\":\"Daily Update\"\n",
    "            })\n",
    "\n",
    "# Cr√©ation du DataFrame final\n",
    "df_from_A = pd.DataFrame(all_rows)\n",
    "\n",
    "# Affichage\n",
    "print(f\"‚úÖ Nombre total de lignes extraites depuis A : {len(df_from_A)}\")\n",
    "\n",
    "# Optionnel : lister les ISIN inconnus avec leur fr√©quence\n",
    "isin_inconnus = [row[\"ISIN\"] for row in all_rows if row[\"Nom\"] == \"inconnu\"]\n",
    "counter = Counter(isin_inconnus)\n",
    "if counter:\n",
    "    print(\"\\nüîé ISIN inconnus rencontr√©s :\")\n",
    "    for isin, count in counter.items():\n",
    "        print(f\"{isin} : {count} fois\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Tous les ISIN ont √©t√© trouv√©s.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1131d",
   "metadata": {},
   "source": [
    "# Traitement de la base historique de abc bourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1b83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Charger l‚Äôhistorique\n",
    "fichier_path1 = \"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\ActionFrancaise_ListeA.csv\"\n",
    "fichier_path2 = \"C:\\\\Users\\\\emerg\\\\Desktop\\\\A_Trading\\\\ActionFrancaise_ListeA1.csv\"\n",
    "\n",
    "# Chargement des deux fichiers CSV avec le bon s√©parateur\n",
    "df1 = pd.read_csv(fichier_path1, sep=';', encoding='utf-8')\n",
    "df2 = pd.read_csv(fichier_path2, sep=';', encoding='ISO-8859-1')\n",
    "\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True).drop_duplicates(subset=[\"ISIN\", \"Date\"])\n",
    "df_concat[\"Source\"] = \"Historique\"\n",
    "\n",
    "# 1. Appliquer les dictionnaires aux donn√©es historiques\n",
    "df_concat[\"Nom\"] = df_concat[\"ISIN\"].map(isin_to_nom).fillna(\"inconnu\")\n",
    "df_concat[\"Ticker\"] = df_concat[\"ISIN\"].map(isin_to_ticker).fillna(\"inconnu\")\n",
    "\n",
    "# 4. Fusion avec les nouvelles donn√©es\n",
    "df_final = pd.concat([df_concat, df_from_A], ignore_index=True).drop_duplicates(subset=[\"ISIN\", \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ac7faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1959900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa89b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Tous les ISIN ont un nom.\n"
     ]
    }
   ],
   "source": [
    "isin_manquants = df_final[df_final[\"Nom\"] == \"inconnu\"][\"ISIN\"]\n",
    "if not isin_manquants.empty:\n",
    "    print(\"\\nüö® ISIN inconnus dans le dataset final :\")\n",
    "    print(isin_manquants.value_counts())\n",
    "else:\n",
    "    print(\"\\n‚úÖ Tous les ISIN ont un nom.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9d0da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(isin_manquants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf01807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_isin_column(df, column=\"ISIN\"):\n",
    "    \"\"\"\n",
    "    Nettoie la colonne ISIN en supprimant la derni√®re lettre\n",
    "    si c'est un caract√®re alphab√©tique.\n",
    "    \"\"\"\n",
    "    def sanitize(isin):\n",
    "        isin = str(isin)\n",
    "        if isin and isin[-1].isalpha():\n",
    "            return isin[:-1]\n",
    "        return isin\n",
    "    \n",
    "    df[column] = df[column].apply(sanitize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e78d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = clean_isin_column(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f9e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Source</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR0000064578</td>\n",
       "      <td>26/07/90</td>\n",
       "      <td>14.350</td>\n",
       "      <td>14.350</td>\n",
       "      <td>14.350</td>\n",
       "      <td>14.350</td>\n",
       "      <td>0</td>\n",
       "      <td>Covivio</td>\n",
       "      <td>Historique</td>\n",
       "      <td>COV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR0000054215</td>\n",
       "      <td>26/07/90</td>\n",
       "      <td>65.250</td>\n",
       "      <td>65.250</td>\n",
       "      <td>65.250</td>\n",
       "      <td>65.250</td>\n",
       "      <td>0</td>\n",
       "      <td>Unibel</td>\n",
       "      <td>Historique</td>\n",
       "      <td>UNBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR0000064578</td>\n",
       "      <td>27/07/90</td>\n",
       "      <td>14.300</td>\n",
       "      <td>14.300</td>\n",
       "      <td>14.300</td>\n",
       "      <td>14.300</td>\n",
       "      <td>0</td>\n",
       "      <td>Covivio</td>\n",
       "      <td>Historique</td>\n",
       "      <td>COV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR0000054215</td>\n",
       "      <td>27/07/90</td>\n",
       "      <td>63.270</td>\n",
       "      <td>63.270</td>\n",
       "      <td>63.270</td>\n",
       "      <td>63.270</td>\n",
       "      <td>0</td>\n",
       "      <td>Unibel</td>\n",
       "      <td>Historique</td>\n",
       "      <td>UNBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR0000064578</td>\n",
       "      <td>30/07/90</td>\n",
       "      <td>13.720</td>\n",
       "      <td>13.720</td>\n",
       "      <td>13.720</td>\n",
       "      <td>13.720</td>\n",
       "      <td>0</td>\n",
       "      <td>Covivio</td>\n",
       "      <td>Historique</td>\n",
       "      <td>COV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959895</th>\n",
       "      <td>US2220702037</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>3.360</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.358</td>\n",
       "      <td>3.401</td>\n",
       "      <td>2884</td>\n",
       "      <td>Coty Inc.</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>COTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959896</th>\n",
       "      <td>FR0000124570</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.220</td>\n",
       "      <td>13.900</td>\n",
       "      <td>14.100</td>\n",
       "      <td>103690</td>\n",
       "      <td>OPmobility (ex Plastic Omnium)</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>OPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959897</th>\n",
       "      <td>LU0569974404</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>30.880</td>\n",
       "      <td>31.740</td>\n",
       "      <td>30.740</td>\n",
       "      <td>31.640</td>\n",
       "      <td>324105</td>\n",
       "      <td>Aperam</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>APAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959898</th>\n",
       "      <td>BE0003853703</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>68.400</td>\n",
       "      <td>69.500</td>\n",
       "      <td>68.300</td>\n",
       "      <td>69.500</td>\n",
       "      <td>18700</td>\n",
       "      <td>Montea C.V.A.</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>MONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959899</th>\n",
       "      <td>FR0010221234</td>\n",
       "      <td>03/10/25</td>\n",
       "      <td>3.555</td>\n",
       "      <td>3.730</td>\n",
       "      <td>3.495</td>\n",
       "      <td>3.710</td>\n",
       "      <td>2129082</td>\n",
       "      <td>Eutelsat Com.</td>\n",
       "      <td>Daily Update</td>\n",
       "      <td>ETL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1959900 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ISIN      Date    Open    High     Low   Close   Volume  \\\n",
       "0        FR0000064578  26/07/90  14.350  14.350  14.350  14.350        0   \n",
       "1        FR0000054215  26/07/90  65.250  65.250  65.250  65.250        0   \n",
       "2        FR0000064578  27/07/90  14.300  14.300  14.300  14.300        0   \n",
       "3        FR0000054215  27/07/90  63.270  63.270  63.270  63.270        0   \n",
       "4        FR0000064578  30/07/90  13.720  13.720  13.720  13.720        0   \n",
       "...               ...       ...     ...     ...     ...     ...      ...   \n",
       "1959895  US2220702037  03/10/25   3.360   3.401   3.358   3.401     2884   \n",
       "1959896  FR0000124570  03/10/25  14.000  14.220  13.900  14.100   103690   \n",
       "1959897  LU0569974404  03/10/25  30.880  31.740  30.740  31.640   324105   \n",
       "1959898  BE0003853703  03/10/25  68.400  69.500  68.300  69.500    18700   \n",
       "1959899  FR0010221234  03/10/25   3.555   3.730   3.495   3.710  2129082   \n",
       "\n",
       "                                    Nom        Source Ticker  \n",
       "0                               Covivio    Historique    COV  \n",
       "1                                Unibel    Historique   UNBL  \n",
       "2                               Covivio    Historique    COV  \n",
       "3                                Unibel    Historique   UNBL  \n",
       "4                               Covivio    Historique    COV  \n",
       "...                                 ...           ...    ...  \n",
       "1959895                       Coty Inc.  Daily Update   COTY  \n",
       "1959896  OPmobility (ex Plastic Omnium)  Daily Update    OPM  \n",
       "1959897                          Aperam  Daily Update   APAM  \n",
       "1959898                   Montea C.V.A.  Daily Update   MONT  \n",
       "1959899                   Eutelsat Com.  Daily Update    ETL  \n",
       "\n",
       "[1959900 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c03e49",
   "metadata": {},
   "source": [
    "# Creation de la base de donn√©e postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ef7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"bourse\",\n",
    "    user=\"olivier\",\n",
    "    password=\"cccc\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0095323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3  # Pas besoin d'installation\n",
    "from sqlalchemy import create_engine,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23084768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table ABC_Bourse supprim√©e si elle existait.\n",
      "‚úÖ Table ABC_Bourse cr√©√©e dans la base 'bourse.db'\n"
     ]
    }
   ],
   "source": [
    "# Supposons que df_final est pr√™t et contient les colonnes nettoy√©es suivantes :\n",
    "# [\"ISIN\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Nom\", \"Ticker\", \"source\"]\n",
    "\n",
    "# Nettoyage : conversion Date + types num√©riques\n",
    "\n",
    "df_final[\"Date\"] = pd.to_datetime(df_final[\"Date\"], format=\"%d/%m/%y\", errors=\"coerce\", dayfirst=True)\n",
    "df_final[\"Open\"] = pd.to_numeric(df_final[\"Open\"], errors=\"coerce\")\n",
    "df_final[\"High\"] = pd.to_numeric(df_final[\"High\"], errors=\"coerce\")\n",
    "df_final[\"Low\"] = pd.to_numeric(df_final[\"Low\"], errors=\"coerce\")\n",
    "df_final[\"Close\"] = pd.to_numeric(df_final[\"Close\"], errors=\"coerce\")\n",
    "df_final[\"Volume\"] = pd.to_numeric(df_final[\"Volume\"], errors=\"coerce\")\n",
    "\n",
    "# Connexion √† la base SQLite locale\n",
    "#engine = create_engine('sqlite:///bourse.db')  # Remplacer par la cha√Æne de connexion √† ta base (PostgreSQL, etc.)\n",
    "\n",
    "# Remplace par tes identifiants PostgreSQL\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:cccc@localhost:5432/bourse\")\n",
    "\n",
    "# Supprimer la table seulement si elle existe\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS ABC_Bourse\"))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"‚úÖ Table ABC_Bourse supprim√©e si elle existait.\")\n",
    "\n",
    "# Cr√©ation / remplacement de la table ABC_Bourse\n",
    "df_final.to_sql(\"ABC_Bourse\", con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"‚úÖ Table ABC_Bourse cr√©√©e dans la base 'bourse.db'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b035856",
   "metadata": {},
   "source": [
    "# Creation de la base de donn√©e Des codes ISIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43481ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isin = clean_isin_column(df_isin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3020648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total initial : 17613\n",
      "Nombre apr√®s d√©duplication : 7008\n"
     ]
    }
   ],
   "source": [
    "# On garde le premier enregistrement par ISIN (tu peux aussi faire 'last' selon ton besoin)\n",
    "df_isin_unique = df_isin.drop_duplicates(subset=\"ISIN\", keep=\"first\")\n",
    "\n",
    "# V√©rif rapide\n",
    "print(f\"Nombre total initial : {len(df_isin)}\")\n",
    "print(f\"Nombre apr√®s d√©duplication : {len(df_isin_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca7fdc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table ISIN_Metadata enregistr√©e dans la base bourse.db.\n"
     ]
    }
   ],
   "source": [
    "df_isin_unique.to_sql(\"ISIN_Metadata\", con=engine, if_exists=\"replace\", index=False)\n",
    "print(\"‚úÖ Table ISIN_Metadata enregistr√©e dans la base bourse.db.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c296612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
